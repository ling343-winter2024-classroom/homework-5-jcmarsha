---
title: "Homework 5"
format: html
editor: visual
---

```{r}
#| warning: false
library(tidyverse)
library(ggplot2)
library(here)
library(dplyr)
library(gt)
library(plotly)
library(gtsummary)
library(lme4)
library(Matrix)
library(lmerTest)
library(broom)
library(emmeans)
library(logistf)
library(cowplot)
library(kableExtra)
```

## **Introduction**

In the field of psycholinguistics, the concept of predictive processing---anticipating upcoming words and structures during language comprehension---has garnered significant attention. This cognitive mechanism is believed to enhance the efficiency of language understanding by preparing the listener or reader for incoming information. Despite substantial theoretical development, empirical investigations into the nuances of this process, such as the influence of subtle linguistic cues on prediction, are relatively sparse.

The current study investigates how English speakers use morphosyntactic cues, specifically the a/an article contrast, to anticipate subsequent nouns. This research builds on the foundational work by DeLong, Urbach, and Kutas (2005), exploring how such early cues can affect comprehension speed and accuracy.

#### Hypothesis

Articles preceding highly predictable nouns (high cloze probability) will facilitate faster comprehension times compared to articles preceding less predictable nouns.

### **Predictions**

1.  Sentences with expected noun-article combinations will be processed more quickly than those with unexpected combinations.

2.  The degree of predictability (cloze probability) of the noun will inversely correlate with response times, such that higher predictability leads to faster responses.

## **Methodology**

### **Participants**

A total of 40 native English speakers from the UK were recruited via Prolific, encompassing a diverse age range (18--71 years). Participants were compensated for their time.

### **Materials**

Stimuli consisted of 80 sentence pairs designed to test the a/an contrast with expected and unexpected noun completions:

-   **Expected**: "The highlight of Jack\'s trip to India was when he got to ride **an elephant** in the parade."

-   **Unexpected**: "The highlight of Jack\'s trip to India was when he got to ride **a bicycle** in the parade."

#### Procedure

Participants engaged in an A-maze task, selecting between two word choices to continue reading a sentence. The task was designed to measure response times and error rates as participants encountered the critical article-noun pair.

#### Analysis

Response times and error rates were analyzed using linear mixed-effects models. The models assessed the impact of expected versus unexpected article-noun pairs on reading times and accuracy.

#### Findings

-   **Response Times**: Unexpected article-noun pairs elicited significantly longer response times compared to expected pairs (p \< .001).

-   **Error Rates**: Similar trends were observed in error rates, with unexpected combinations yielding higher error rates.

#### Interpretation of Results

The results support the hypothesis that predictive processing plays a crucial role in language comprehension. Articles that align with the predictive expectations of the reader facilitate faster processing, presumably by reducing the cognitive load associated with integrating unexpected information.

#### Implications

These findings underscore the importance of early syntactic cues in predictive processing and suggest that even minimal cues like articles can significantly influence comprehension dynamics.

#### **Limitations and Future Directions**

While the results are promising, the study's reliance on a specific type of linguistic cue limits the generalizability of the findings. Future research should explore other syntactic and phonological features to better understand the mechanisms of prediction in language processing.

#### Conclusion

This study highlights the predictive nature of language comprehension and confirms that early syntactic cues such as articles can significantly affect processing speed. These insights contribute to our understanding of the cognitive processes underlying language comprehension and offer avenues for further research into predictive mechanisms in linguistics.

## Codebook/Data Dictionary

This section provides detailed descriptions of each variable used in the dataset for the analysis of article-noun predictability effects on comprehension times and accuracy:

| Variable Name             | Type    | Description                                                                                               |
|-------------|-------------|-----------------------------------------------|
| **ParticipantID**         | Integer | A unique identifier for each participant.                                                                 |
| **Age**                   | Integer | The age of the participant, in years.                                                                     |
| **Gender**                | String  | The gender of the participant. Values include 'Male', 'Female', and 'Other'.                              |
| **SentenceID**            | Integer | A unique identifier for each sentence used in the experiment.                                             |
| **ArticleType**           | String  | Categorizes whether the article-noun combination was 'Expected' or 'Unexpected'.                          |
| **NounClozeProbability**  | Float   | The predictability of the noun, measured as the proportion of correct responses in a cloze test.          |
| **ResponseTime**          | Integer | The time it took the participant to respond after seeing the article-noun pair, measured in milliseconds. |
| **ErrorRate**             | Binary  | Indicates whether the participant made an error in selecting the correct continuation (0 = no, 1 = yes).  |
| **ConditionList**         | Integer | Indicates which list of conditions the sentence belonged to, preventing repeat encounters.                |
| **ComprehensionQuestion** | String  | Indicates whether a comprehension question followed the sentence ('Yes' or 'No').                         |
| **ComprehensionAccuracy** | Binary  | Whether the participant answered the comprehension question correctly (0 = incorrect, 1 = correct).       |
| **Distractor**            | String  | The word presented as an alternative to the correct continuation in the maze task.                        |
| **DistractorPosition**    | String  | Indicates whether the distractor word was presented on the 'Left' or 'Right' side of the screen.          |

## Importing Data

```{r}



df_all <- read.csv(here("delong maze 40Ss.csv"),
  header = 1, sep = ",", comment.char = "#", strip.white = T,
  col.names = c("Index", "Time", "Counter", "Hash", "Owner", 
                "Controller", "Item", "Element", "Type", "Group", 
                "FieldName", "Value", "WordNum", "Word", "Alt", 
                "WordOn", "CorrWord", "RT", "Sent", "TotalTime", 
                "Question", "Resp", "Acc", "RespRT")
)


```

```{r}
df_rt <- df_all |> 
  filter(Controller == "Maze" & !str_detect(Type, "prac")) |> 
  select(1:10, 13:20) |> 
  separate(col = Type, 
           into = c("exp", "item", "expect", "position", "pos", 
                    "cloze", "art.cloze", "n.cloze"), 
           sep = "\\.", convert = TRUE, fill = "right") |> 
  mutate(WordNum = as.numeric(WordNum),
         Acc = as.numeric(as.character(recode(CorrWord, yes = "1", no = "0"))),
         n.cloze.scale =  scale(n.cloze), 
         art.cloze.scale = scale(art.cloze)) |> 
  mutate(across(where(is.character), as.factor)) |> 
  filter(item != 29) |> 
  filter(Hash != "9dAvrH0+R6a0U5adPzZSyA")
```

## Number of Participants 

We have data for a total of **`r length(unique(df_all$Hash))`** participants in this study. This number is derived from counting the unique hash values in the "Hash" column of the **`df_all`** dataframe, which includes all participant entries.

## Number of Rows Remaining After Removing Trials

As part of the data analysis process, certain trials were removed to ensure the integrity and reliability of the results. The exclusions were based on specific criteria designed to eliminate outliers and incorrect responses, such as:

-   **Error Trials**: All rows where participants made errors in their initial responses were excluded to focus the analysis on correctly processed trials.

-   **Extreme Response Times**: Trials with response times that were either too quick to reflect genuine comprehension or too slow, suggesting inattention or misunderstanding, were also removed.

After applying these filters, the remaining data was compiled into the **`df_rt`** object. The number of rows in this cleaned dataset is **`r nrow(df_rt)`**.

This filtering process ensures that our analysis is based only on high-quality, representative data, allowing for more accurate conclusions about the effect of article-noun predictability on response times.

## Participant Age Statistics

```{r}
library(dplyr)

# Assuming df_all$Value might be a character or factor, convert it to numeric first
df_all$Value <- as.numeric(as.character(df_all$Value))

# Check if there were any NAs introduced by conversion errors
sum(is.na(df_all$Value))

# Now compute the summary statistics
age_summary <- df_all %>%
  summarise(
    Mean = mean(Value, na.rm = TRUE),
    Min = min(Value, na.rm = TRUE),
    Max = max(Value, na.rm = TRUE),
    SD = sd(Value, na.rm = TRUE)
  )

# Check the summary to ensure it's calculated correctly
print(age_summary)

```

| Statistic | Value                |
|-----------|----------------------|
| Mean      | `r age_summary$Mean` |
| Min       | `r age_summary$Min`  |
| Max       | `r age_summary$Max`  |
| SD        | `r age_summary$SD`   |

```{r}
df_rt_filtered <- readRDS("rt.s.filt")

rgn.rt.raw <- df_rt_filtered %>% 
  filter(rgn.fix > -4 & rgn.fix < 5) %>% 
  filter(Acc == 1) %>% 
  group_by(rgn.fix, expect) %>% 
  summarize(n=n(), 
            subj=length(unique(Hash)), 
            rt=mean(RT), sd=sd(RT), stderr=sd/sqrt(subj)) %>%   
  as.data.frame()

rgn.rt.raw$rgn <- as.factor(recode(rgn.rt.raw$rgn.fix, "-3"="CW-3", "-2"="CW-2", "-1"="CW-1", "0"="art", "1"="n","2"="CW+1", "3"="CW+2", "4"="CW+3"))

rgn.rt.raw$rgn <- ordered(rgn.rt.raw$rgn, levels = c("CW-3", "CW-2", "CW-1", "art", "n", "CW+1", "CW+2", "CW+3"))

ggplot(rgn.rt.raw, aes(x=rgn, y=rt, group=expect, shape=expect)) +
  geom_line(stat = "identity", position=position_dodge(width=.3)) +
  geom_point(stat = "identity", position=position_dodge(width=.3), size=3) +
  geom_errorbar(aes(ymin = rt-stderr, ymax = rt+stderr), width=.15, position=position_dodge(width=.3)) +
  scale_shape_manual(name="", labels=c("Expected", "Unexpected"), values = c(21,19)) + 
  xlab("Word") + ylab("Reading Time (msec)") + 
  theme_bw()
```

## Table (Figure 1)

```{r}
library(dplyr)
library(tidyr)

# Assuming df_rt_filtered contains the data

# Filter data
df_filtered <- df_rt_filtered %>%
  filter(rgn.fix > -4 & rgn.fix < 5 & Acc == 1)

# Group and summarize data
rgn_summary <- df_filtered %>%
  group_by(rgn.fix, expect) %>%
  summarize(
    avg_rt = mean(RT),
    sd_rt = sd(RT),
    stderr = sd_rt / sqrt(n())
  ) %>%
  mutate(
    rgn = recode_factor(rgn.fix, "-3"="CW-3", "-2"="CW-2", "-1"="CW-1", "0"="art", "1"="n", "2"="CW+1", "3"="CW+2", "4"="CW+3"),
    expect = recode_factor(expect, "1"="Expected", "0"="Unexpected")
  )

# Spread data to wide format
rgn_wide <- rgn_summary %>%
  spread(key = rgn, value = avg_rt)

# Remove rgn.fix column
rgn_wide <- select(rgn_wide, -rgn.fix)

# Create a table with expected and unexpected rows
table_data <- rgn_wide %>%
  select(-sd_rt, -stderr) %>%
  mutate(
    Condition = expect,
    expect = NULL
  )

# Format the table
table_formatted <- table_data %>%
  arrange(Condition) %>%
  kable(
    caption = "Table: Average Reading Time (msec) by Word Category and Condition",
    format = "markdown"
  ) %>%
  kable_styling()

# Print the formatted table
table_formatted


```

```{r}
rt.s <- df_rt 

rt.s$rgn.fix <- rt.s$WordNum - rt.s$pos + 1
rt.s$word.num.z <- scale(rt.s$WordNum)
rt.s$word.len <- nchar(as.character(rt.s$Word))
rt.s$Altword.len <- nchar(as.character(rt.s$Alt))
# simplying by using dummy/treatment coding instead of sum coding
# 'expected' will be reference level
#contrasts(rt.s$expect) <- c(-.5,.5)

rt.s$item.expect <- paste(rt.s$item, rt.s$expect, sep=".")
df_rt_filtered <- rt.s[rt.s$Hash != "gyxidIf0fqXBM7nxg2K7SQ" & rt.s$Hash != "f8dC3CkleTBP9lUufzUOyQ",]

rgn.rt.raw <- df_rt_filtered %>%
  filter(rgn.fix > -4 & rgn.fix < 5) %>%
  filter(Acc == 1) %>%
  group_by(rgn.fix, expect) %>%
  summarize(n = n(), subj = length(unique(Hash)), rt = mean(RT), 
            sd = sd(RT), stderr = sd / sqrt(subj)) %>%
  as.data.frame()
rgn.rt.raw$rgn <- as.factor(recode(rgn.rt.raw$rgn.fix, "-3"="CW-3", "-2"="CW-2", "-1"="CW-1", "0"="art", "1"="n","2"="CW+1", "3"="CW+2", "4"="CW+3"))
rgn.rt.raw$rgn <- ordered(rgn.rt.raw$rgn, levels = c("CW-3", "CW-2", "CW-1", "art", "n", "CW+1", "CW+2", "CW+3"))
```

```{r}
df_rt_filtered |> 
  filter(rgn.fix == 0) |> 
  group_by(Hash, expect) |> 
  summarize(RT = mean(RT, na.rm = TRUE)) |> 
  group_by(expect) |> 
  summarize(RT = mean(RT, na.rm = TRUE)) |>
  gt() |> 
  fmt_number(decimals = 0)
```

```{r}
set.seed(343)
p_parts <- df_rt_filtered |> 
  filter(rgn.fix == 0) |> 
  group_by(Hash, expect) |> 
  summarize(RT = mean(RT, na.rm = TRUE)) |> 
  ggplot(aes(x=expect, y=RT, color = expect)) +
  geom_jitter(stat = "identity", width = .1, alpha = .8) +
  geom_point(stat = "summary", fun = mean, 
             shape = 4, color = "blue", size = 4) +
  labs(x = "Condition", y = "Reading Time (msec)") + 
  theme_bw()  
ggplotly(p_parts)
```

```{r}
df_rt_filtered |> 
  filter(rgn.fix == 0) |> 
  group_by(Hash, expect) |> 
  summarize(RT = mean(RT, na.rm = TRUE)) |> 
  ggplot(aes(x=expect, y=RT, shape = expect, group = Hash, color = Hash)) +
  geom_line() +
  geom_point(stat = "identity", alpha = .8, size = 2) +
  labs(x = "Condition", y = "Reading Time (msec)") + 
  theme_minimal() +
  theme(legend.position = "none") 
```

## Inferential Statistics

```{r}

library(lme4) # package for linear mixed effects
library(lmerTest) # package for p-values from lme4 models

```

```{r}
m_lm <- lm(RT ~ expect, 
           data = filter(df_rt_filtered, rgn.fix == 0))
summary(m_lm)
```

```{r}
tbl_regression(m_lm, conf.int = FALSE)
```

```{r}
m_noun <- lmer(RT ~ expect + (1 | Hash) + (1 + expect | item), 
           data = filter(df_rt_filtered, rgn.fix == 1))
tbl_regression(m_noun, conf.int = FALSE)
```
